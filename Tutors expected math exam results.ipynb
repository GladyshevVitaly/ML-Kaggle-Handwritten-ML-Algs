{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutors - expected math exam results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tutors-expected-math-exam-results/submission_example.csv\n",
      "/kaggle/input/tutors-expected-math-exam-results/train.csv\n",
      "/kaggle/input/tutors-expected-math-exam-results/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/tutors-expected-math-exam-results/train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      "Id                     10000 non-null int64\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "mean_exam_points       10000 non-null float64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 937.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>lesson_price</th>\n",
       "      <th>qualification</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "      <th>biology</th>\n",
       "      <th>english</th>\n",
       "      <th>geography</th>\n",
       "      <th>history</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4999.50000</td>\n",
       "      <td>45.878000</td>\n",
       "      <td>1.986800</td>\n",
       "      <td>1699.105000</td>\n",
       "      <td>1.719500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>64.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>8.043929</td>\n",
       "      <td>1.772213</td>\n",
       "      <td>524.886654</td>\n",
       "      <td>0.792264</td>\n",
       "      <td>0.484147</td>\n",
       "      <td>0.339484</td>\n",
       "      <td>0.312406</td>\n",
       "      <td>0.225436</td>\n",
       "      <td>0.176274</td>\n",
       "      <td>0.137933</td>\n",
       "      <td>13.536823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2499.75000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4999.50000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7499.25000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2150.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3950.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id           age  years_of_experience  lesson_price  \\\n",
       "count  10000.00000  10000.000000         10000.000000  10000.000000   \n",
       "mean    4999.50000     45.878000             1.986800   1699.105000   \n",
       "std     2886.89568      8.043929             1.772213    524.886654   \n",
       "min        0.00000     23.000000             0.000000    200.000000   \n",
       "25%     2499.75000     40.000000             0.000000   1300.000000   \n",
       "50%     4999.50000     46.000000             2.000000   1500.000000   \n",
       "75%     7499.25000     51.000000             3.000000   2150.000000   \n",
       "max     9999.00000     68.000000            10.000000   3950.000000   \n",
       "\n",
       "       qualification       physics     chemistry       biology       english  \\\n",
       "count   10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean        1.719500      0.375000      0.132900      0.109600      0.053700   \n",
       "std         0.792264      0.484147      0.339484      0.312406      0.225436   \n",
       "min         1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         2.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "max         4.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          geography       history  mean_exam_points  \n",
       "count  10000.000000  10000.000000      10000.000000  \n",
       "mean       0.032100      0.019400         64.340800  \n",
       "std        0.176274      0.137933         13.536823  \n",
       "min        0.000000      0.000000         32.000000  \n",
       "25%        0.000000      0.000000         55.000000  \n",
       "50%        0.000000      0.000000         63.000000  \n",
       "75%        0.000000      0.000000         73.000000  \n",
       "max        1.000000      1.000000        100.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 781.4 KB\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Id', 'mean_exam_points'], axis = 1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.00e+01, 0.00e+00, 1.40e+03, ..., 0.00e+00, 1.00e+00, 0.00e+00],\n",
       "       [4.80e+01, 4.00e+00, 2.85e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [3.90e+01, 0.00e+00, 1.20e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       ...,\n",
       "       [3.40e+01, 1.00e+00, 1.25e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [3.30e+01, 3.00e+00, 1.10e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [3.50e+01, 0.00e+00, 1.45e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 1 columns):\n",
      "mean_exam_points    10000 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "y = data[['mean_exam_points']]\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63., 86., 53., ..., 58., 51., 59.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.values.flatten()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/kaggle/input/tutors-expected-math-exam-results/test.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "Id                     10000 non-null int64\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 859.5 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 781.4 KB\n"
     ]
    }
   ],
   "source": [
    "test_X = test.drop(['Id'], axis = 1)\n",
    "test_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.60e+01, 3.00e+00, 1.05e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [4.30e+01, 3.00e+00, 1.85e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [5.20e+01, 1.00e+00, 1.55e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       ...,\n",
       "       [3.30e+01, 5.00e+00, 1.10e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [4.80e+01, 0.00e+00, 1.75e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [4.90e+01, 5.00e+00, 2.00e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test_X.values\n",
    "test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf_Reg:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        prediction = np.mean(self.labels)\n",
    "        return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    # Класс узла\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_reg(left_labels, right_labels, current_variance):\n",
    "\n",
    "    # доля выбоки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    return current_variance - p * np.var(left_labels) - (1 - p) * np.var(right_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, labels, index, t):\n",
    "    # Разбиение датасета в узле\n",
    "    \n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split_reg(data, labels):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_leaf = 5\n",
    "\n",
    "    current_variance = np.var(labels)\n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique([row[index] for row in data])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_quality = quality_reg(true_labels, false_labels, current_variance)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_reg_depth_lim(data, labels, depth_lim = 20, depth = 0):\n",
    "\n",
    "    quality, t, index = find_best_split_reg(data, labels)\n",
    "    #print(\"q: {} t: {} ind: {}\".format(quality, t, index))\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    if quality == 0 or depth >= depth_lim:\n",
    "        return Leaf_Reg(data, labels)\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree_reg_depth_lim(true_data, true_labels, depth_lim, depth + 1)\n",
    "    false_branch = build_tree_reg_depth_lim(false_data, false_labels, depth_lim, depth + 1)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_item(item, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf_Reg):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "\n",
    "    if item[node.index] <= node.t:\n",
    "        return pred_item(item, node.true_branch)\n",
    "    else:\n",
    "        return pred_item(item, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_predict_m(X, trees_list, coef_list, eta):\n",
    "    # Реализуемый алгоритм градиентного бустинга будет инициализироваться нулевыми значениями,\n",
    "    # поэтому все деревья из списка trees_list уже являются дополнительными и при предсказании прибавляются с шагом eta\n",
    "    return np.array([sum([eta * coef * pred_item(x, tree) for tree, coef in zip(trees_list, coef_list)]) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_real, prediction):\n",
    "    return (sum((y_real - prediction)**2)) / len(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(y, z):\n",
    "    return (y - z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_fit_lt(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    err_min = np.inf\n",
    "    \n",
    "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            tree = build_tree_reg_depth_lim(X_train, y_train, max_depth)\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict_m(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict_m(X_test, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            target = gb_predict_m(X_train, trees, coefs, eta)\n",
    "            \n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            tree = build_tree_reg_depth_lim(X_train, bias(y_train, target), max_depth)\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict_m(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict_m(X_test, trees, coefs, eta)))\n",
    "        \n",
    "#             if test_errors[-1]-0.00005 > err_min:\n",
    "#                 print(len(trees))\n",
    "#                 break\n",
    "#             elif test_errors[-1] < err_min:\n",
    "#                 err_min = test_errors[-1]\n",
    "\n",
    "        if not (i+1)%10:\n",
    "            print(i+1)\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, train_errors, test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_plot(n_trees, train_err, test_err):\n",
    "    plt.xlabel('Iteration number')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlim(2, n_trees+1)\n",
    "    plt.plot(list(range(2, n_trees+1)), train_err[1:], label='train error')\n",
    "    plt.plot(list(range(2, n_trees+1)), test_err[1:], label='test error')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_mtr(n_trees_l, max_depth_l, eta_l, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "    err_min = np.inf\n",
    "    for tr in n_trees_l:\n",
    "        for dp in max_depth_l:\n",
    "            for et in eta_l:\n",
    "                coefs = [1] * tr # для простоты примем коэффициенты равными 1\n",
    "                trees, train_errors, test_errors = gb_fit_lt(tr, dp, X_train, X_test, y_train, y_test, coefs, et)\n",
    "                train_prediction = gb_predict_m(X_train, trees, coefs, et)\n",
    "                print(f'Ошибка алгоритма из {len(trees)} деревьев глубиной {dp} с шагом {et} на тренировочной выборке: {mean_squared_error(y_train, train_prediction)}')\n",
    "                test_prediction = gb_predict_m(X_test, trees, coefs, et)\n",
    "                err = mean_squared_error(y_test, test_prediction)\n",
    "                print(f'Ошибка алгоритма из {len(trees)} деревьев глубиной {dp} с шагом {et} на тестовой выборке: {err}')\n",
    "                print(test_errors)\n",
    "                if err_min > err:\n",
    "                    tr_b = len(trees)\n",
    "                    dp_b = dp\n",
    "                    et_b = et\n",
    "                    err_min = err\n",
    "                get_error_plot(len(train_errors), train_errors, test_errors)\n",
    "    print(f'Лучшие параметры: Ошибка алгоритма из {tr_b} деревьев глубиной {dp_b} с шагом {et_b} на тестовой выборке: {err_min}')\n",
    "    return tr_b, dp_b, et_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees_l = [350]\n",
    "max_depth_l = [2, 3, 4, 5, 6]\n",
    "eta_l = [0.1]\n",
    "\n",
    "tr_b, dp_b, et_b = grid_mtr(n_trees_l, max_depth_l, eta_l, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees_l = [350]\n",
    "max_depth_l = [5]\n",
    "eta_l = [0.15, 0.14, 0.13, 0.12, 0.11, 0.1, 0.099, 0.098, 0.097, 0.096, 0.095]\n",
    "\n",
    "tr_b, dp_b, et_b = grid_mtr(n_trees_l, max_depth_l, eta_l, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees_l = [100]\n",
    "max_depth_l = [5]\n",
    "eta_l = [0.15, 0.14, 0.13, 0.12, 0.11, 0.1, 0.099, 0.098, 0.097, 0.096, 0.095]\n",
    "\n",
    "tr_b, dp_b, et_b = grid_mtr(n_trees_l, max_depth_l, eta_l, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "Ошибка алгоритма из 210 деревьев глубиной 5 с шагом 0.07 на тренировочной выборке: 33.520182744724615\n",
      "Ошибка алгоритма из 210 деревьев глубиной 5 с шагом 0.07 на тестовой выборке: 42.27577410809791\n",
      "[4330.028, 3750.5030536825248, 3249.5947333419467, 2816.4650343540534, 2441.6783867472095, 2117.504920733779, 1837.1479673378913, 1594.655812541384, 1384.9510169579576, 1203.7141780787445, 1046.7958297828072, 911.3103376965482, 793.9261554831147, 692.4325029550612, 604.7807034408875, 528.9022039721093, 463.2230385915187, 406.44562838249414, 357.3542918624468, 314.8830104635539, 278.1479871824635, 246.39762685987364, 218.81357341485122, 195.04535493457425, 174.4101964411635, 156.58233364007117, 141.23451694949108, 127.93265184575598, 116.48688231881331, 106.51773382362998, 97.92200339001782, 90.41989206171912, 83.97968493141784, 78.43077085961173, 73.59696406001741, 69.41897817367506, 65.83118336515744, 62.741381699820735, 59.98593396573965, 57.68156685090445, 55.50921910117293, 53.626742905244676, 52.116508766719974, 50.76813780186317, 49.51972110263978, 48.56263922624057, 47.77188372173305, 46.958997342441364, 46.350193752722525, 45.716024570955554, 45.181099700777, 44.72876047747681, 44.34662356223419, 44.03926837871382, 43.794877519033435, 43.48095013812368, 43.28686386692748, 43.13153043267728, 43.02447562919801, 42.879449363501564, 42.75753961119996, 42.67610882393989, 42.606685781722696, 42.536072676419074, 42.43352136372669, 42.33961144894755, 42.32175877200896, 42.27714174358044, 42.2911625664193, 42.26991213054087, 42.211796527948394, 42.22525072555839, 42.22558202959508, 42.21195629971505, 42.23532521848883, 42.24034839010322, 42.21900180920635, 42.209092093304044, 42.11610147274671, 42.11043647517243, 42.10025188738685, 42.094596924400285, 42.105896805160796, 42.04027435778258, 42.04523334292127, 41.96752364849888, 41.97777047365716, 41.96720575067036, 41.96976615193896, 41.98199030386873, 41.974182198191414, 41.976373904034546, 41.963730912864875, 41.96052566062775, 41.9686791571554, 41.97176875035536, 41.983569752189645, 41.99949427272964, 42.0093818923895, 42.008098870610525, 41.95531495249616, 41.96195513474885, 41.98836687185858, 41.955111554904114, 41.95150393047746, 41.96933070153834, 41.987205061468615, 41.97814612655991, 41.9830076794952, 41.98303276946992, 41.98529136893212, 41.993460250092646, 41.97375346661857, 41.97961700141058, 41.98733431723831, 41.95011938448186, 41.94155330089483, 41.95824662392046, 41.96715112036264, 42.00843856807298, 42.02061802588957, 42.03785410342338, 42.05200410479166, 42.07090351914105, 42.077442201106805, 42.05518768771084, 42.054334357366635, 42.050009411952004, 42.03107854767098, 42.026696201394955, 42.01750312628786, 42.05165301706965, 42.05630576522265, 42.03579544607479, 42.033453628608406, 42.0454807979147, 42.02724025660843, 42.055648704744335, 42.07739647323336, 42.09522540851517, 42.10478915667931, 42.10477370133688, 42.110359825687226, 42.11378885040732, 42.11337530403785, 42.11528176712328, 42.10197256538814, 42.10365021317955, 42.1060000655151, 42.09869360851212, 42.09513593952315, 42.09669914469043, 42.083579401835756, 42.059629651513, 42.05617352065553, 42.07221213880954, 42.06675283714304, 42.07367522502985, 42.076745949054725, 42.04787745326581, 42.04386570521973, 42.04828191023617, 42.04801226985484, 42.06533267471468, 42.06762639604495, 42.053435860823484, 42.08440589118585, 42.09674333107257, 42.078630150434954, 42.08785575684666, 42.07979605897802, 42.081604896858614, 42.086092147388115, 42.06924135188593, 42.08541823749504, 42.09780051595092, 42.08981566731038, 42.09996272357833, 42.10168513846648, 42.109136354479745, 42.1009884918204, 42.10535105429192, 42.10429008213732, 42.105218826580014, 42.109190989165754, 42.11947592556024, 42.12318385392415, 42.12128744360798, 42.13879217933289, 42.14942141889296, 42.160219244723564, 42.17350424811645, 42.16452228008736, 42.16601706268958, 42.17884995805889, 42.177957061873556, 42.161156138465, 42.163622379764796, 42.16507667821479, 42.16590663002432, 42.17172702993333, 42.17086810563102, 42.167133733452964, 42.182089646137804, 42.19497931477637, 42.199801853584184, 42.219088548496146, 42.23520282936839, 42.25489440030105, 42.25592698318928]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxV9Z3/8dcnNytbEiBgBDSxxSoCAgLVSituLNq6TMdqWyuO/h7U32jVznTRdjpqW2fsz+mi09aOTrHWWrWtWqmlLjAudVwwKLIqiYgSFoksgQCBLJ/fH+eE3oSb3Gw3J7l5Px+P+7jnfM72uSdwP/ds36+5OyIiIm3JiDoBERHp/VQsREQkKRULERFJSsVCRESSUrEQEZGkMqNOIBWGDx/uJSUlUachItKnLFu27EN3L0o0LS2LRUlJCWVlZVGnISLSp5jZe61N02koERFJSsVCRESSUrEQEZGk0vKahYikj7q6OiorK6mtrY06lbSRm5vL6NGjycrKavcyKhYi0qtVVlYyePBgSkpKMLOo0+nz3J3t27dTWVlJaWlpu5fTaSgR6dVqa2sZNmyYCkU3MTOGDRvW4SM1FQsR6fVUKLpXZ/ZnWhaLhurN1O7cHHUaIiJpIy2LRWzvB2zasC7qNEQkDezatYuf//znnVr2nHPOYdeuXd2cUTTSslgA1NbsjDoFEUkDbRWLhoaGNpddtGgRBQUF3ZpPfX19m+PtXa6j0vZuqLq9KhYi0nU33HAD77zzDpMmTeLss8/m3HPP5ZZbbqG4uJjly5ezZs0aLrjgAjZu3EhtbS3XXXcd8+fPB/7W9FBNTQ1z585lxowZvPTSS4waNYrHH3+cvLy8Ztuqqqriqquu4v333wfgJz/5Caeeeio333wzmzdvZsOGDQwfPpxjjz222fi///u/c8UVV1BVVUVRURH33nsvRx11FJdffjlDhw7ljTfeYMqUKfzwhz/s9H5I22JRv7c66hREpJvd8qfVrNm8u1vXOe7IIdz0mRNanX7bbbexatUqli9fDsBzzz3H0qVLWbVq1aFbTxcsWMDQoUPZv38/06ZN47Of/SzDhg1rtp7y8nIefPBB7rnnHj73uc/xyCOPcOmllzab57rrruOrX/0qM2bM4P3332f27NmsXbsWgGXLlvHiiy+Sl5fHzTff3Gz8M5/5DJdddhnz5s1jwYIFXHvttfzxj38EYN26dSxevJhYLNal/ZS2xaJxf3qcJxSR3mf69OnNnlG48847eeyxxwDYuHEj5eXlhxWL0tJSJk2aBMBJJ53Ehg0bDlvv4sWLWbNmzaHx3bt3s2fPHgDOO++8Zkci8eMvv/wyjz76KABf+tKX+MY3vnFovosuuqjLhQLStFg4hh/o3l8fIhK9to4AetLAgQMPDT/33HMsXryYl19+mQEDBjBz5syEzzDk5OQcGo7FYuzfv/+weRobG3n55ZcPOz3VcpuJxuPF3xrb1nwdkZYXuBvJwFQsRKQbDB48+NCv+0Sqq6spLCxkwIABvPXWW7zyyiud3tasWbP46U9/emi86dRXMp/4xCd46KGHAHjggQeYMWNGp3NoTdoWi5iKhYh0g2HDhnHqqacyfvx4vv71rx82fc6cOdTX1zNx4kS+853vcPLJJ3d6W3feeSdlZWVMnDiRcePG8Ytf/KLdy917771MnDiR+++/nzvuuKPTObTG3L3bVxq1CaMG+G+u+xQnfuPJqFMRkS5au3Ytxx9/fNRppJ1E+9XMlrn71ETzp+mRRYyc+tYPG0VEpGNSVizMLNfMlprZm2a22sxuCeO/MrN3zWx5+JoUxs3M7jSzCjNbYWZT4tY1z8zKw9e8ZNt2yyCnYW+qPpqISL+TyruhDgBnuHuNmWUBL5rZX8JpX3f3P7SYfy4wNnx9HLgL+LiZDQVuAqYCDiwzs4Xu3upTd24x8hpruvnjiIj0Xyk7svBA0zd2Vvhq6wLJ+cCvw+VeAQrMrBiYDTzj7jvCAvEMMKfNbVsGA11HFiIi3SWl1yzMLGZmy4FtBF/4r4aTbg1PNf3YzJpuPh4FbIxbvDKMtRZvXUaMgb4fb2y73RYREWmflBYLd29w90nAaGC6mY0HbgSOA6YBQ4FvhrMnamDd24g3Y2bzzazMzMoO1jWQYc6Bvbp9VkSkO/TI3VDuvgt4Dpjj7lvCU00HgHuB6eFslcCYuMVGA5vbiLfcxt3uPtXdp+bkBk8/1lRv7+6PIiL9TFeaKIegMcB9+/Z1Y0bRSOXdUEVmVhAO5wFnAW+F1yGw4Hn0C4BV4SILgcvCu6JOBqrdfQvwFDDLzArNrBCYFcZalxG0g7Jv945u/1wi0r9EXSw62yR5subTOyqVRxbFwLNmtgJ4jeCaxRPAA2a2ElgJDAe+H86/CFgPVAD3AP8I4O47gO+F63gN+G4Ya5VlBDd57VefFiLSRfFNlDc9wX377bczbdo0Jk6cyE033QTA3r17OffccznxxBMZP348Dz/8MHfeeSebN2/m9NNP5/TTTz9s3cuWLeO0007jpJNOYvbs2WzZsgWAmTNn8q1vfYvTTjuNO+6447DxJUuWMHnyZCZMmMAVV1zBgQMHgKBJ9O9+97vMmDGD3//+9926H1J266y7rwAmJ4if0cr8DlzdyrQFwIL2bjsjbGHx4F61PCuSVv5yA2xd2b3rPGICzL2t1cktmyh/+umnKS8vZ+nSpbg75513Hi+88AJVVVUceeSR/PnPfwaCNqPy8/P50Y9+xLPPPsvw4cObrbeuro6vfOUrPP744xQVFfHwww/z7W9/mwULgq+6Xbt28fzzzwPwpz/96dB4bW0tY8eOZcmSJRx77LFcdtll3HXXXVx//fUA5Obm8uKLL3bvPiJNn+DOCI8s6nRkISLd7Omnn+bpp59m8uTJTJkyhbfeeovy8nImTJjA4sWL+eY3v8lf//pX8vPz21zP22+/zapVqzj77LOZNGkS3//+96msrDw0/eKLL242f9P422+/TWlpKcceeywA8+bN44UXXmh1ue6Slk2UNx1ZNOxXB0giaaWNI4Ce4u7ceOONfPnLXz5s2rJly1i0aBE33ngjs2bN4l//9V/bXM8JJ5zAyy+/nHB6a02SJ2vPr7uaJG8pPY8sYkENdHWAJCJd1LKJ8tmzZ7NgwQJqaoJnjjdt2sS2bdvYvHkzAwYM4NJLL+VrX/sar7/+esLlm3zsYx+jqqrqULGoq6tj9erVSfM57rjj2LBhAxUVFQDcf//9nHbaaV3+nMmk55FFRga1ngVqplxEuii+ifK5c+dy++23s3btWk455RQABg0axG9+8xsqKir4+te/TkZGBllZWdx1110AzJ8/n7lz51JcXMyzzz57aL3Z2dn84Q9/4Nprr6W6upr6+nquv/56Tjih7Q6ecnNzuffee7nooouor69n2rRpXHXVVanbAaG0bKJ86tSp/uSnt/HusJlM+8qvo05HRLpATZSnhpooD+21QWQe1JGFiEh3SNtiUZsxkMw69WkhItId0rdYZA4mp0HFQiQdpOPp8ih1Zn+mbbE4mDWYvAb1aSHS1+Xm5rJ9+3YVjG7i7mzfvp3c3NwOLZeWd0MB1GfnM7BGRxYifd3o0aOprKykqqoq6lTSRm5uLqNHj+7QMmlbLBpzChjiNeAOlqiVcxHpC7KysigtLY06jX4vbU9DkVdIpjVSq/ahRES6LG2LRcbAoQDs2alDVxGRrkrbYpE1cBgAe9UBkohIl6VtscgZHBxZ7K/WkYWISFelbbHIHRK0HX9gj44sRES6Km2LxYD8oFjU71XXqiIiXZW2xWJIYVAsGlUsRES6LGXFwsxyzWypmb1pZqvN7JYwXmpmr5pZuZk9bGbZYTwnHK8Ip5fErevGMP62mc1uz/YHDRocNFO+X73liYh0VSqPLA4AZ7j7icAkYI6ZnQz8APixu48FdgJXhvNfCex0948CPw7nw8zGAZcAJwBzgJ+bWSzZxs2M3TaYjAPqLU9EpKtSViw80NQ4U1b4cuAM4A9h/D7ggnD4/HCccPqZZmZh/CF3P+Du7wIVwPT25FCTMZjMgyoWIiJdldJrFmYWM7PlwDbgGeAdYJe714ezVAKjwuFRwEaAcHo1MCw+nmCZ+G3NN7MyMytrakNmf2wwOSoWIiJdltJi4e4N7j4JGE1wNJCou6umpiQTNeDkbcRbbutud5/q7lOLiooAqM3MJ7dBHSCJiHRVj9wN5e67gOeAk4ECM2tqwHA0sDkcrgTGAITT84Ed8fEEy7SpPnsIAxvV8qyISFel8m6oIjMrCIfzgLOAtcCzwN+Hs80DHg+HF4bjhNP/x4MG7BcCl4R3S5UCY4Gl7cmhIaeAQa4+LUREuiqVTZQXA/eFdy5lAL9z9yfMbA3wkJl9H3gD+GU4/y+B+82sguCI4hIAd19tZr8D1gD1wNXu3tCeBDyvkAEcoP7APjJzBnTrhxMR6U9SVizcfQUwOUF8PQnuZnL3WuCiVtZ1K3BrR3PIyCsEYM+uDykceVRHFxcRkVDaPsENEBsUNCZYo2bKRUS6JK2LRXZYLPbv/jDiTERE+ra0LhY5YcuztXvUPpSISFekdbEY2NTy7B4dWYiIdEVaF4tBhSMBqN+rPi1ERLoirYtFfn4hBzwT9urIQkSkK9K6WMRiGVTbEDJqdc1CRKQr0rpYAOzOyCdbxUJEpEvSvljsy8wnp25X1GmIiPRpaV8sDmQXMqhBxUJEpCvSvljU5wxlcKOaKRcR6Yq0LxaNecMYwl4a6w5GnYqISJ+V9sXCBgUP5u3esTXiTERE+q60LxZZg5uKxQcRZyIi0nelfbHIHjICgH27VCxERDor7YvFgIKgyY/aXdsizkREpO9K+2IxeOgRANTtUZ8WIiKdlfbFomBYcBrK1ZigiEinpaxYmNkYM3vWzNaa2Wozuy6M32xmm8xsefg6J26ZG82swszeNrPZcfE5YazCzG7oSB65ublU+0DYp8YERUQ6K2V9cAP1wD+7++tmNhhYZmbPhNN+7O7/ET+zmY0DLgFOAI4EFpvZseHknwFnA5XAa2a20N3XtDeR3RlDyFL7UCIinZayYuHuW4At4fAeM1sLjGpjkfOBh9z9APCumVUA08NpFe6+HsDMHgrnbXexqIkVkH1wZyc+hYiIQA9dszCzEmAy8GoYusbMVpjZAjMrDGOjgI1xi1WGsdbiLbcx38zKzKysqqr5xez9WYUMqFf7UCIinZXyYmFmg4BHgOvdfTdwF/ARYBLBkccPm2ZNsLi3EW8ecL/b3ae6+9SioqJm0w7mFDK4obrzH0JEpJ9L5TULzCyLoFA84O6PArj7B3HT7wGeCEcrgTFxi48GNofDrcXbpSF3KPm+G9zBEtUeERFpSyrvhjLgl8Bad/9RXLw4brYLgVXh8ELgEjPLMbNSYCywFHgNGGtmpWaWTXARfGGHchlURJY1UFOtO6JERDojlUcWpwJfAlaa2fIw9i3g82Y2ieBU0gbgywDuvtrMfkdw4boeuNrdGwDM7BrgKSAGLHD31R1JJDYkeDCvetsmBhUUJZlbRERaSuXdUC+S+HrDojaWuRW4NUF8UVvLJZNbGBzM1GzfRHCpREREOiLtn+AGGDg0uHlq/84OXeoQEZFQvygWBSNGA1BXrT4tREQ6o18Ui8KhRRzwTHyPmikXEemMflEsYrEMdloBsX1qeVZEpDP6RbEAqI4Vkl2rW2dFRDqj3xSLfdnDGFinZspFRDqj3xSL2pwi8hvUmKCISGf0m2LROLCIAq/GG+qjTkVEpM/pN8XCBo0gZs7uHbp9VkSko/pNscjKD57i3rVtU8SZiIj0Pf2mWOSFTX7s3a5iISLSUf2mWAwaHjT5UbtrS8SZiIj0Pf2mWBSOCIpFvZr8EBHpsH5TLIYMKaDGc2HvtqhTERHpc/pNsTAzdmYUkrVX7UOJiHRUvykWANWZReQd0JGFiEhH9atisS93BPl1akxQRKSjUtkH9xgze9bM1prZajO7LowPNbNnzKw8fC8M42Zmd5pZhZmtMLMpceuaF85fbmbzOptT3cBihjXuwBsbuv4BRUT6kTaLhZldGjd8aotp1yRZdz3wz+5+PHAycLWZjQNuAJa4+1hgSTgOMBcYG77mA3eF2xkK3AR8HJgO3NRUYDrKhhSTbfXs2aHrFiIiHZHsyOKf4ob/s8W0K9pa0N23uPvr4fAeYC0wCjgfuC+c7T7ggnD4fODXHngFKDCzYmA28Iy773D3ncAzwJwkeSeUVRj0mLdj63udWVxEpN9KViysleFE462vxKwEmAy8Cox09y0QFBRgRDjbKGBj3GKVYay1eMttzDezMjMrq6pKfF1i0PAxANRsU7EQEemIZMXCWxlONJ6QmQ0CHgGud/fdbc3ayvZbizcPuN/t7lPdfWpRUVHCDQwZWQJA7Y7KJFmLiEi8zCTTjzOzFQRf2B8JhwnHj0m2cjPLIigUD7j7o2H4AzMrdvct4WmmpntZK4ExcYuPBjaH8Zkt4s8l23YiRUeMod4zaKxW+1AiIh2RrFgc39kVm5kBvwTWuvuP4iYtBOYBt4Xvj8fFrzGzhwguZleHBeUp4N/iLmrPAm7sTE7Z2VlstUIyatQ+lIhIR7RZLNy92cl9MxsGfAp4392XJVn3qcCXgJVmtjyMfYugSPzOzK4E3gcuCqctAs4BKoB9wD+EOewws+8Br4Xzfdfdd7TjsyW0K3M4eft1N5SISEe0WSzM7AngBndfFZ4yeh0oIzgldbe7/6S1Zd39RVq/CH5mgvkduLqVdS0AFrSVa3vVZI+gqHZDd6xKRKTfSHaBu9TdV4XD/0BwC+tnCE4TtXnrbG91cMBIhjV+GHUaIiJ9SrJiURc3fCbBqaKm5yYaU5VUSg0ZxSD2U1uzM+pMRET6jGTFYqOZfcXMLgSmAE8CmFkekJXq5FIhln8kANu36FkLEZH2SlYsrgROAC4HLnb3XWH8ZODeFOaVMgOKSgDYtfXdaBMREelDkt0NtQ24KkH8WeDZVCWVSkOP/AgA+7epWIiItFeyu6EWtjXd3c/r3nRSr+jIEuo8RuNOnYYSEWmvZA/lnULQLtODBO06tbs9qN4qOzuLShtO5m41+SEi0l7JisURwNnA54EvAH8GHnT31alOLJV2Zh/BwP1q8kNEpL3avMDt7g3u/qS7zyO4qF0BPGdmX+mR7FJkX96RDK3TU9wiIu2VtKc8M8sxs78DfkPwhPWdwKNtL9W71Q8ZQxE7qD+wP+pURET6hGQXuO8DxgN/AW6Je5q7T8scejRshKpN71B8zPio0xER6fWSHVl8CTgWuA54ycx2h689ZtZW3xS9Wl5R0Lr6zk0VEWciItI3JHvOIulpqr6osOlZiyo9ayEi0h5pWQySGTG6hHrPoGGHnrUQEWmPflkscrJz2GbDie3RsxYiIu3RL4sFwI6sIxi0T89aiIi0R78tFjUDRjO8bnPUaYiI9An9tlg0FBzDMHapXwsRkXZIWbEwswVmts3MVsXFbjazTWa2PHydEzftRjOrMLO3zWx2XHxOGKswsxu6K7+sEcEdUVvfXdtdqxQRSVupPLL4FTAnQfzH7j4pfC0CMLNxwCUEfWfMAX5uZjEziwE/A+YC44DPh/N2Wf6o4wDYVflWd6xORCStJWtIsNPc/QUzK2nn7OcDD7n7AeBdM6sApofTKtx9PYCZPRTOu6ar+R1RGtScg9vKu7oqEZG0F8U1i2vMbEV4mqowjI0iaAq9SWUYay1+GDObb2ZlZlZWVVWVNIn8/AK2MZTYzvWd+hAiIv1JTxeLu4CPAJOALcAPw3iifjK8jfjhQfe73X2qu08tKipqVzLbskYxaO/77ZpXRKQ/69Fi4e4fhM2eNwL38LdTTZXAmLhZRwOb24h3i5qBR1FUpwfzRESS6dFiYWbFcaMXAk13Si0ELgmbQy8FxgJLgdeAsWZWambZBBfB2+zqtSMaCkoZym7279btsyIibUnZBW4zexCYCQw3s0rgJmCmmU0iOJW0AfgygLuvNrPfEVy4rgeudveGcD3XAE8BMWBBd/bSlz1iLGyArRtWUzpxRnetVkQk7aTybqjPJwj/so35bwVuTRBfBCzqxtQOKRhzPCyF6sq3QMVCRKRV/fYJboDi0nE0unFwq561EBFpS78uFoMGDWazjSRrp561EBFpS78uFgDb8koZulfPWoiItKXfF4v9+R/lyIZNNNQdjDoVEZFeq98Xi9jIcWRZA1vf7babrERE0k6/LxYFR08A4MN334w4ExGR3qvfF4tRYyfS6MaBzV1um1BEJG31+2IxeHB+cEfUjnVRpyIi0mv1+2IBsC2vhMJ970SdhohIr6ViAezPH8uR9ZtoqDsQdSoiIr2SigUQO3Ii2dbApvLlUaciItIrqVgARWOnAbC9fGnEmYiI9E4qFsBRYyew13Oo36TbZ0VEElGxALIyM3k/6xgG79LtsyIiiahYhHblH8+Yg+/gjQ1RpyIi0uuoWDQpnshAavlgw9qoMxER6XVULEKFx0wFYOs6XeQWEWkpZcXCzBaY2TYzWxUXG2pmz5hZefheGMbNzO40swozW2FmU+KWmRfOX25m81KV79HHnUSdxzi48Y1UbUJEpM9K5ZHFr4A5LWI3AEvcfSywJBwHmAuMDV/zgbsgKC4EfXd/HJgO3NRUYLpb3oABbIiVMPDDFalYvYhIn5ayYuHuLwA7WoTPB+4Lh+8DLoiL/9oDrwAFZlYMzAaecfcd7r4TeIbDC1C3qSo4kZIDb9FYX5+qTYiI9Ek9fc1ipLtvAQjfR4TxUcDGuPkqw1hr8ZTIOGo6A6mlct2yVG1CRKRP6i0XuC1BzNuIH74Cs/lmVmZmZVVVVZ1K4ogTPglA1Zq/dmp5EZF01dPF4oPw9BLh+7YwXgmMiZtvNLC5jfhh3P1ud5/q7lOLioo6ldxRx4xjO/lQ+VqnlhcRSVc9XSwWAk13NM0DHo+LXxbeFXUyUB2epnoKmGVmheGF7VlhLCUyYhm8lzeOkbt1kVtEJF4qb519EHgZ+JiZVZrZlcBtwNlmVg6cHY4DLALWAxXAPcA/Arj7DuB7wGvh67thLGX2jziJ0Y2b2bNjayo3IyLSp2SmasXu/vlWJp2ZYF4Hrm5lPQuABd2YWpsGHzsD3vspG95YwoQzv9hTmxUR6dV6ywXuXmPs5NPY79nUrnsu6lRERHoNFYsW8gYMYF3OeIo+fDXqVEREeg0ViwRqik+mpOE9dlclvPFKRKTfUbFIIH/cWQC8u+zJiDMREekdVCwSGDt5BjWeR13F81GnIiLSK6hYJJCTnUN53kSKt78CnvCBcRGRfkXFohX7jj6DUb6VLetXRp2KiEjkVCxaMebkCwGofPWxiDMREYmeikUrjir9GO9klDDwvSVRpyIiEjkVizZsHXkax9auZG/19qhTERGJlIpFG4ZM/DSZ1kjF/+pUlIj0byoWbThu6ulUUYCveTz5zCIiaUzFog1ZWVmsG3YWx+95mf17dkadjohIZFQskhg87WJyrI63n3846lRERCKjYpHECdPOYjNFxNY8GnUqIiKRUbFIIhbLYP3IWRy3t4zdVZuiTkdEJBIqFu0w8rQrybIG1j39X1GnIiISCRWLdhg77iRWZY6n+J3f4Y0NUacjItLjIikWZrbBzFaa2XIzKwtjQ83sGTMrD98Lw7iZ2Z1mVmFmK8xsShQ57znhC4xq3EL5q2q2XET6nyiPLE5390nuPjUcvwFY4u5jgSXhOMBcYGz4mg/c1eOZAhPOvoxqH8j+l3QqSkT6n950Gup84L5w+D7ggrj4rz3wClBgZsU9ndygQYNZccTfMX73C2x7b01Pb15EJFJRFQsHnjazZWY2P4yNdPctAOH7iDA+CtgYt2xlGGvGzOabWZmZlVVVVaUk6WM+/c/UE2PjE7enZP0iIr1VVMXiVHefQnCK6Woz+1Qb81qC2GE9Ern73e4+1d2nFhUVdVeezYwaU8rrBbM4Yduf2P2h+ucWkf4jkmLh7pvD923AY8B04IOm00vh+7Zw9kpgTNzio4HIvqmLZn+DLOopf+SWqFIQEelxPV4szGygmQ1uGgZmAauAhcC8cLZ5QFPrfQuBy8K7ok4GqptOV0Xho+Mm82r+HCZs/gPbN70TVRoiIj0qiiOLkcCLZvYmsBT4s7s/CdwGnG1m5cDZ4TjAImA9UAHcA/xjz6fc3OgLb8Ex3n/k21GnIiLSIzJ7eoPuvh44MUF8O3BmgrgDV/dAau12VOnH+OvIi/jktt+y4Y1nKZl8etQpiYikVG+6dbZPmfCFW9nKMPzP/0RjfV3U6YiIpJSKRScVFAxl/Un/Qmn9epb/7ntRpyMiklIqFl1wyrmXszRvBuPf/ikbV70UdToiIimjYtEFlpFByeX/zU7Lxx79P9TWqDc9EUlPKhZdNGJkMRtn3sERDVuo+MUX1CqtiKQlFYtuMHXmefz1I19jfM1LvLngOvDDHjAXEenTVCy6yWlfvJHnCy5kUuX9vPnb70SdjohIt1Kx6CYZsQxOufq/eWngWZxY/p+s+M0NOsIQkbShYtGNsrMymXLtb3lx4CwmVtzFiv+6Eq8/GHVaIiJdpmLRzXJzcvj4Vx9iybAvMHHrI1T8xxnUVL0fdVoiIl2iYpECWZkxzrjm5/zPCf/GqP3raPzZKZQvXqDTUiLSZ6lYpIiZccZFV7P+s4vYmHEkY1/8KuX/cSbb1y+LOjURkQ5TsUix8ROnUvL1v/LU0V9jRM1bDPv1Gbz943PZtvbFqFMTEWk38zQ8NTJ16lQvKyuLOo3DvFdZyVsLf8T0Dx6m0GpYnzeehgkXc8xplxIbODTq9ESknzOzZe4+NeE0FYuet3nbh6x4/A7GbnqEj7CJOjJ5d8h0GHsWY06aS17x8WCJepMVEUkdFYteqvZgPctefZ69ZQ9y/K7nGWNBT7LbM4bzYf4JePEkhn50OsNLJpBRMBoyYhFnLCLpTMWiD6ita2DlyuV8uPJpBm56iTEH1lFqWw9NP0gm27OKqRkwhob8o8kYUkz2kBHkFR7BoGHFDCgYiQ0aAdkDI/wUItKXtVUserynPEksNyvGtCknwZSTADfNgvsAAApLSURBVDhY38iajZvY+tZSaj9YR8bOdxm0932G7drE6F1vMNj2J1xPHZkcsFxqMwZwMDaA+syB1McG0Jg1EI9lQUYWHsvGYlkQy8IysyGWTUYsG8vMxjKzguFYDLMMzDLALBjOCF+HxmPNhzPi5jPDMLDgHoqmk2qHzq5Z83srmuLWInDYcuE9GS3P0gXj1mK8aZ3WLGgtlrFWT/m1cSowHU4T9rkfin0s3762f0eOa3NynykWZjYHuAOIAf/t7rclWaRPy87MYFzpGMaVjmkWb2x0Pqw5wPs7d7Fnx1b27djCgeoPqN9ThdVUkXGwmljdXmIN+8iu30d23T5yG3eR41vJpp5MGsiyerKo/9s49WSbWssV6c9WTL6lzel9oliYWQz4GXA2UAm8ZmYL3X1NtJn1vIwMY8SQXEYMOQKOPgKY1K7l3J26BudgQyN19Y0cbGhkd30jdQ3BcF1dI3V1tdQdPEhD/UEaGhugsRFvbKTRg3d3D98baGx08EYaGxvwcNi9kcZGx70hHPdD24a434UtxuN/gBl+aNzxFtObj8dPj/+d3+zUaivbcrzFtkg4cNi2AHP/2/posWCL9bX24zJRvCO/Q72VuTvyYzbYT82PkFpbPHG+7d9YR9bb2tzBvJYglmgNh0/o0P7twHpbW3EQbplvK5+tnbFW423m0L55TztmCvDVVrbaR4oFMB2ocPf1AGb2EHA+0O+KRWeZGdmZRnZmBuREnY2I9DV95aG8UcDGuPHKMHaImc03szIzK6uqqurR5ERE0l1fKRaJriY2O5hy97vdfaq7Ty0qKuqhtERE+oe+UiwqgfgrvaOBzRHlIiLS7/SVYvEaMNbMSs0sG7gEWBhxTiIi/UafuMDt7vVmdg3wFMGtswvcfXXEaYmI9Bt9olgAuPsiYFHUeYiI9Ed95TSUiIhESMVCRESSSsuGBM2sCngv6jxaGA58GHUSbVB+XaP8uq6359gf8jva3RM+e5CWxaI3MrOy1lpz7A2UX9cov67r7Tn29/x0GkpERJJSsRARkaRULHrO3VEnkITy6xrl13W9Pcd+nZ+uWYiISFI6shARkaRULEREJCkVixQwszFm9qyZrTWz1WZ2XRi/2cw2mdny8HVOhDluMLOVYR5lYWyomT1jZuXhe2FEuX0sbh8tN7PdZnZ9lPvPzBaY2TYzWxUXS7i/LHCnmVWY2QozmxJRfreb2VthDo+ZWUEYLzGz/XH78RcR5dfq39PMbgz339tmNjui/B6Oy22DmS0P41Hsv9a+U3ru36C769XNL6AYmBIODwbWAeOAm4GvRZ1fmNcGYHiL2P8DbgiHbwB+0AvyjAFbgaOj3H/Ap4ApwKpk+ws4B/gLQT8sJwOvRpTfLCAzHP5BXH4l8fNFuP8S/j3D/ytvEvTpWAq8A8R6Or8W038I/GuE+6+175Qe+zeoI4sUcPct7v56OLwHWEuLnv16qfOB+8Lh+4ALIsylyZnAO+4e6RP57v4CsKNFuLX9dT7waw+8AhSYWXFP5+fuT7t7fTj6CkE/MJFoZf+15nzgIXc/4O7vAhUEXSunTFv5mZkBnwMeTGUObWnjO6XH/g2qWKSYmZUAk4FXw9A14WHhgqhO84QceNrMlpnZ/DA20t23QPCPExgRWXZ/cwnN/5P2lv0Hre+vpN0AR+AKgl+aTUrN7A0ze97MPhlVUiT+e/a2/fdJ4AN3L4+LRbb/Wnyn9Ni/QRWLFDKzQcAjwPXuvhu4C/gIMAnYQnBoG5VT3X0KMBe42sw+FWEuCVnQ0dV5wO/DUG/af21J2g1wTzKzbwP1wANhaAtwlLtPBv4J+K2ZDYkgtdb+nr1q/wGfp/kPlsj2X4LvlFZnTRDr0j5UsUgRM8si+KM+4O6PArj7B+7e4O6NwD2k+NC6Le6+OXzfBjwW5vJB06Fq+L4tqvxCc4HX3f0D6F37L9Ta/uo13QCb2Tzg08AXPTyZHZ7e2R4OLyO4JnBsT+fWxt+zN+2/TODvgIebYlHtv0TfKfTgv0EVixQIz3H+Eljr7j+Ki8efM7wQWNVy2Z5gZgPNbHDTMMGF0FUEXdXOC2ebBzweRX5xmv2i6y37L05r+2shcFl4R8rJQHXTqYKeZGZzgG8C57n7vrh4kZnFwuFjgLHA+gjya+3vuRC4xMxyzKw0zG9pT+cXOgt4y90rmwJR7L/WvlPoyX+DPXlFv7+8gBkEh3wrgOXh6xzgfmBlGF8IFEeU3zEEd5u8CawGvh3GhwFLgPLwfWiE+3AAsB3Ij4tFtv8IitYWoI7gV9uVre0vglMAPyP4xbkSmBpRfhUE562b/g3+Ipz3s+Hf/U3gdeAzEeXX6t8T+Ha4/94G5kaRXxj/FXBVi3mj2H+tfaf02L9BNfchIiJJ6TSUiIgkpWIhIiJJqViIiEhSKhYiIpKUioWIiCSlYiFpxcxqwvcSM/tCN6/7Wy3GX+rO9Xc3M7vczH4adR6SHlQsJF2VAB0qFk0PWrWhWbFw9090MKc+pR37Q/oRFQtJV7cBnwz7G/iqmcUs6N/htbDhui8DmNnMsJ+A3xI8vISZ/TFsYHF1UyOLZnYbkBeu74Ew1nQUY+G6V1nQR8jFcet+zsz+YEG/Eg+ET+I2E87zAzNbambrmhqma3lkYGZPmNnMpm2Hyywzs8VmNj1cz3ozOy9u9WPM7EkL+oW4KW5dl4bbW25m/xX3RHKNmX3XzF4FTumuP4akgVQ/eaiXXj35AmrC95nAE3Hx+cC/hMM5QBlBXwkzgb1Aady8TU/B5hE0QTEsft0JtvVZ4BmCvjdGAu8T9D8wE6gmaJcnA3gZmJEg5+eAH4bD5wCLw+HLgZ/GzfcEMDMcdsInmwna9noayAJOBJbHLb+F4Cnfps8yFTge+BOQFc73c+CyuPV+Luq/o16975XZ4eoi0jfNAiaa2d+H4/kEbfocBJZ60G9Ck2vN7MJweEw43/Y21j0DeNDdGwgadnsemAbsDtddCWBBT2slwIsJ1tHUMNyycJ5kDgJPhsMrgQPuXmdmK1ss/4yHjd6Z2aNhrvXAScBr4YFOHn9rgK6BoLE6kWZULKS/MOAr7v5Us2BwWmdvi/GzgFPcfZ+ZPQfktmPdrTkQN9xA6//nDiSYp57mp4rj86hz96a2ehqblnf3xrCl1CYt2/PxMN/73P3GBHnUhkVPpBlds5B0tYeg+8kmTwH/N2zmGTM7Nmxxt6V8YGdYKI4j6JKySV3T8i28AFwcXhcpIuiisztaSd0ATDKzDDMbQ+eaZD/bgn6a8wh6Uftfggbn/t7MRsChfpyP7oZ8JY3pyELS1Qqg3szeJGg59A6C0zOvhxeZq0jcbeyTwFVmtoKgxdNX4qbdDawws9fd/Ytx8ccILga/SfDL/RvuvjUsNl3xv8C7BKeZVhG0cNpRLxK07vpR4LfuXgZgZv9C0FNiBkFLq1cDkXZdK72bWp0VEZGkdBpKRESSUrEQEZGkVCxERCQpFQsREUlKxUJERJJSsRARkaRULEREJKn/D0bDlzfuGmehAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: Ошибка алгоритма из 210 деревьев глубиной 5 с шагом 0.07 на тестовой выборке: 42.27577410809791\n"
     ]
    }
   ],
   "source": [
    "n_trees_l = [210]\n",
    "max_depth_l = [5]\n",
    "eta_l = [0.07]\n",
    "\n",
    "tr_b, dp_b, et_b = grid_mtr(n_trees_l, max_depth_l, eta_l, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка алгоритма из 10 деревьев глубиной 3 с шагом 1 на тренировочной выборке: 41.85032639612631\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 3 с шагом 1 на тестовой выборке: 42.89189222152119\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 3 с шагом 0.1 на тренировочной выборке: 572.8473411680155\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 3 с шагом 0.1 на тестовой выборке: 574.893182109124\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 5 с шагом 1 на тренировочной выборке: 35.759331381826996\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 5 с шагом 1 на тестовой выборке: 43.89510402271741\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 5 с шагом 0.1 на тренировочной выборке: 562.3994214587036\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 5 с шагом 0.1 на тестовой выборке: 563.976102338061\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 3 с шагом 1 на тренировочной выборке: 34.81778222149674\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 3 с шагом 1 на тестовой выборке: 42.39123563605255\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 3 с шагом 0.1 на тренировочной выборке: 40.53835649064402\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 3 с шагом 0.1 на тестовой выборке: 41.71821615536555\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 1 на тренировочной выборке: 24.808303083037085\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 1 на тестовой выборке: 51.84322827702307\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 0.1 на тренировочной выборке: 34.61620200766768\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 0.1 на тестовой выборке: 40.00489589817885"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры: Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 0.1 на тестовой выборке: 40.00489589817885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_fit_lt_half_div(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    half_n = X_train.shape[0] // 2\n",
    "        \n",
    "    for i in range(n_trees):\n",
    "        if i % 2:\n",
    "            b = 1\n",
    "        else:\n",
    "            b = 0\n",
    "        beg_b = half_n*b\n",
    "        end_b = half_n*(b+1)\n",
    "        X_tr = X[beg_b : end_b, :]\n",
    "        y_tr = y[beg_b : end_b]\n",
    "        \n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            \n",
    "            tree = build_tree_reg_depth_lim(X_tr, y_tr, max_depth)\n",
    "\n",
    "            train_errors.append(mean_squared_error(y_tr, gb_predict_m(X_tr, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict_m(X_test, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            target = gb_predict_m(X_tr, trees, coefs, eta)\n",
    "\n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            tree = build_tree_reg_depth_lim(X_tr, bias(y_tr, target), max_depth)\n",
    "\n",
    "            train_errors.append(mean_squared_error(y_tr, gb_predict_m(X_tr, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict_m(X_test, trees, coefs, eta)))\n",
    "\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, train_errors, test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_mtr_hd(n_trees_l, max_depth_l, eta_l, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    err_min = np.inf\n",
    "    for tr in n_trees_l:\n",
    "        for dp in max_depth_l:\n",
    "            for et in eta_l:\n",
    "                coefs = [1] * tr # для простоты примем коэффициенты равными 1\n",
    "                trees, train_errors, test_errors = gb_fit_lt_half_div(tr, dp, X_train, X_test, y_train, y_test, coefs, et)\n",
    "                train_prediction = gb_predict_m(X_train, trees, coefs, et)\n",
    "                print(f'Ошибка алгоритма из {tr} деревьев глубиной {dp} с шагом {et} на тренировочной выборке: {mean_squared_error(y_train, train_prediction)}')\n",
    "                test_prediction = gb_predict_m(X_test, trees, coefs, et)\n",
    "                err = mean_squared_error(y_test, test_prediction)\n",
    "                print(f'Ошибка алгоритма из {tr} деревьев глубиной {dp} с шагом {et} на тестовой выборке: {err}')\n",
    "                if err_min > err:\n",
    "                    tr_b = tr\n",
    "                    dp_b = dp\n",
    "                    et_b = et\n",
    "                    err_min = err\n",
    "                get_error_plot(tr, train_errors, test_errors)\n",
    "    print(f'Лучшие параметры: Ошибка алгоритма из {tr} деревьев глубиной {dp} с шагом {et} на тестовой выборке: {err_min}')\n",
    "    return tr_b, dp_b, et_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_trees_l = [100]\n",
    "# max_depth_l = [3]\n",
    "# eta_l = [0.1]\n",
    "\n",
    "# grid_mtr_hd(n_trees_l, max_depth_l, eta_l, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка алгоритма из 10 деревьев глубиной 3 с шагом 1 на тренировочной выборке: 42.70422172191151\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 3 с шагом 1 на тестовой выборке: 41.539402682141215\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 3 с шагом 0.1 на тренировочной выборке: 571.9243308818674\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 3 с шагом 0.1 на тестовой выборке: 573.9409296079313\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 5 с шагом 1 на тренировочной выборке: 41.473279828165296\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 5 с шагом 1 на тестовой выборке: 41.03750497923822\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 5 с шагом 0.1 на тренировочной выборке: 563.2971153354056\n",
    "\n",
    "Ошибка алгоритма из 10 деревьев глубиной 5 с шагом 0.1 на тестовой выборке: 565.1061224587446\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 3 с шагом 1 на тренировочной выборке: 42.21129533444066\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 3 с шагом 1 на тестовой выборке: 41.23236827909047\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 3 с шагом 0.1 на тренировочной выборке: 41.59138863736706\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 3 с шагом 0.1 на тестовой выборке: 40.98707632425514\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 1 на тренировочной выборке: 42.028156812894004\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 1 на тестовой выборке: 40.08066139900216\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 0.1 на тренировочной выборке: 38.020462790374985\n",
    "\n",
    "Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 0.1 на тестовой выборке: 36.069617631755264\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры: Ошибка алгоритма из 100 деревьев глубиной 5 с шагом 0.1 на тестовой выборке: 36.069617631755264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_fit_fin(n_trees, max_depth, X, y, coefs, eta):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    # Будем записывать ошибки\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            tree = build_tree_reg_depth_lim(X, y, max_depth)\n",
    "            \n",
    "            errors.append(mean_squared_error(y, gb_predict_m(X, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            target = gb_predict_m(X, trees, coefs, eta)\n",
    "            \n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            tree = build_tree_reg_depth_lim(X, bias(y, target), max_depth)\n",
    "            \n",
    "            errors.append(mean_squared_error(y, gb_predict_m(X, trees, coefs, eta)))\n",
    "\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_fit_fin_hd(n_trees, max_depth, X, y, coefs, eta):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    # Будем записывать ошибки\n",
    "    errors = []\n",
    "    \n",
    "    half_n = X.shape[0] // 2\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "\n",
    "        if i % 2:\n",
    "            b = 1\n",
    "        else:\n",
    "            b = 0\n",
    "        beg_b = half_n*b\n",
    "        end_b = half_n*(b+1)\n",
    "        X_b = X[beg_b : end_b, :]\n",
    "        y_b = y[beg_b : end_b]\n",
    "\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            tree = build_tree_reg_depth_lim(X_b, y_b, max_depth)\n",
    "            \n",
    "            errors.append(mean_squared_error(y_b, gb_predict_m(X_b, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            target = gb_predict_m(X_b, trees, coefs, eta)\n",
    "            \n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            tree = build_tree_reg_depth_lim(X_b, bias(y_b, target), max_depth)\n",
    "            \n",
    "            errors.append(mean_squared_error(y_b, gb_predict_m(X_b, trees, coefs, eta)))\n",
    "\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 105\n",
    "max_depth = 5\n",
    "eta = 0.07\n",
    "coefs = [1] * n_trees # для простоты примем коэффициенты равными 1\n",
    "\n",
    "trees, errors = gb_fit_fin(n_trees, max_depth, X, y, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54.94829841, 63.09314131, 48.1657401 , ..., 54.96670569,\n",
       "       64.41162285, 69.30510236])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = gb_predict_m(test_X, trees, coefs, eta)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>54.948298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>63.093141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>48.165740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>91.531405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>89.291018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19995</td>\n",
       "      <td>42.081525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19996</td>\n",
       "      <td>79.031543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19997</td>\n",
       "      <td>54.966706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19998</td>\n",
       "      <td>64.411623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19999</td>\n",
       "      <td>69.305102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  mean_exam_points\n",
       "0     10000         54.948298\n",
       "1     10001         63.093141\n",
       "2     10002         48.165740\n",
       "3     10003         91.531405\n",
       "4     10004         89.291018\n",
       "...     ...               ...\n",
       "9995  19995         42.081525\n",
       "9996  19996         79.031543\n",
       "9997  19997         54.966706\n",
       "9998  19998         64.411623\n",
       "9999  19999         69.305102\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = test[['Id']].copy()\n",
    "res = pd.concat([res, pd.DataFrame(prediction, columns=['mean_exam_points'])], axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"viv_reg_03.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
